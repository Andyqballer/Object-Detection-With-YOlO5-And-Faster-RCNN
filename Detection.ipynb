{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOStCgLoKagxqvRivCuLwE8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andyqballer/Object-Detection-With-YOlO5-And-Faster-RCNN/blob/main/Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrUulCW6-z1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad7e0be-49b1-4469-b0ae-e0a6bd676c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations...\n",
            "loading annotations into memory...\n",
            "Done (t=22.84s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading images: 100%|██████████| 100/100 [00:00<00:00, 28956.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=18.45s)\n",
            "creating index...\n",
            "index created!\n",
            "Starting Faster R-CNN training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   6%|▌         | 3/50 [02:30<39:25, 50.33s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from pycocotools.coco import COCO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import zipfile\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "class ObjectDetectionTrainer:\n",
        "    def __init__(self, root_dir='/content/coco_subset', num_images=100):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.num_images = num_images\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.setup_directories()\n",
        "        self.install_dependencies()\n",
        "\n",
        "    def setup_directories(self):\n",
        "        self.images_dir = self.root_dir / 'images'\n",
        "        self.annotations_dir = self.root_dir / 'annotations'\n",
        "        self.labels_dir = self.root_dir / 'labels'\n",
        "        self.yolo_dir = Path('/content/yolov5')\n",
        "\n",
        "        for dir_path in [self.root_dir, self.images_dir, self.annotations_dir, self.labels_dir]:\n",
        "            dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def install_dependencies(self):\n",
        "        packages = [\n",
        "            'opencv-python-headless',\n",
        "            'pycocotools',\n",
        "            'tqdm',\n",
        "            'pyyaml'\n",
        "        ]\n",
        "        subprocess.run(['pip', 'install'] + packages, check=True)\n",
        "        subprocess.run(['apt-get', 'update'], check=True)\n",
        "        subprocess.run(['apt-get', 'install', '-y', 'libgl1-mesa-glx'], check=True)\n",
        "\n",
        "    def download_coco(self):\n",
        "        ann_url = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "        ann_file = self.root_dir / 'annotations.zip'\n",
        "\n",
        "        if not ann_file.exists():\n",
        "            print(\"Downloading annotations...\")\n",
        "            r = requests.get(ann_url)\n",
        "            r.raise_for_status()\n",
        "            ann_file.write_bytes(r.content)\n",
        "\n",
        "            with zipfile.ZipFile(ann_file, 'r') as zip_ref:\n",
        "                zip_ref.extractall(self.annotations_dir)\n",
        "            ann_file.unlink()\n",
        "\n",
        "        annotation_file = self.annotations_dir / 'annotations' / 'instances_train2017.json'\n",
        "        coco = COCO(str(annotation_file))\n",
        "        img_ids = coco.getImgIds()[:self.num_images]\n",
        "\n",
        "        for img_id in tqdm(img_ids, desc=\"Downloading images\"):\n",
        "            img = coco.loadImgs(img_id)[0]\n",
        "            img_path = self.images_dir / img['file_name']\n",
        "            if not img_path.exists():\n",
        "                img_url = f\"http://images.cocodataset.org/train2017/{img['file_name']}\"\n",
        "                r = requests.get(img_url)\n",
        "                r.raise_for_status()\n",
        "                img_path.write_bytes(r.content)\n",
        "\n",
        "        print(\"Dataset download complete!\")\n",
        "\n",
        "    def load_dataset(self):\n",
        "        annotation_file = self.annotations_dir / 'annotations' / 'instances_train2017.json'\n",
        "        coco = COCO(str(annotation_file))\n",
        "        img_ids = coco.getImgIds()\n",
        "        images = []\n",
        "        annotations = []\n",
        "        unique_labels = set()\n",
        "\n",
        "        for img_id in img_ids:\n",
        "            img_info = coco.loadImgs(img_id)[0]\n",
        "            img_path = self.images_dir / img_info['file_name']\n",
        "            if img_path.exists():\n",
        "                img_annotations = coco.getAnnIds(img_id)\n",
        "                if not img_annotations:\n",
        "                    continue\n",
        "\n",
        "                images.append(str(img_path))\n",
        "                anns = coco.loadAnns(img_annotations)\n",
        "\n",
        "                boxes = []\n",
        "                labels = []\n",
        "                for ann in anns:\n",
        "                    x, y, w, h = ann['bbox']\n",
        "                    boxes.append([x, y, x + w, y + h])\n",
        "                    labels.append(ann['category_id'])\n",
        "                    unique_labels.add(ann['category_id'])\n",
        "\n",
        "                annotations.append({\n",
        "                    'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
        "                    'labels': torch.tensor(labels, dtype=torch.int64)\n",
        "                })\n",
        "\n",
        "        return images, annotations, unique_labels\n",
        "\n",
        "    def prepare_yolo_dataset(self, images, annotations, unique_labels):\n",
        "        self.labels_dir.mkdir(exist_ok=True)\n",
        "        label_map = {label: idx for idx, label in enumerate(sorted(unique_labels))}\n",
        "\n",
        "        for img_path, ann in zip(images, annotations):\n",
        "            img_filename = Path(img_path).name\n",
        "            label_filename = Path(img_filename).stem + '.txt'\n",
        "            label_path = self.labels_dir / label_filename\n",
        "\n",
        "            with open(label_path, 'w') as f:\n",
        "                img = Image.open(img_path)\n",
        "                img_width, img_height = img.size\n",
        "\n",
        "                for box, label in zip(ann['boxes'], ann['labels']):\n",
        "                    x, y, x2, y2 = box.tolist()\n",
        "                    center_x = (x + (x2 - x) / 2) / img_width\n",
        "                    center_y = (y + (y2 - y) / 2) / img_height\n",
        "                    width = (x2 - x) / img_width\n",
        "                    height = (y2 - y) / img_height\n",
        "\n",
        "                    yolo_label = label_map[label.item()]\n",
        "                    f.write(f\"{yolo_label} {center_x} {center_y} {width} {height}\\n\")\n",
        "\n",
        "        return label_map\n",
        "\n",
        "    def setup_yolo_training(self, unique_labels):\n",
        "        if not self.yolo_dir.exists():\n",
        "            print(\"Cloning YOLOv5 repository...\")\n",
        "            subprocess.run(['git', 'clone', 'https://github.com/ultralytics/yolov5.git', str(self.yolo_dir)], check=True)\n",
        "\n",
        "        req_file = self.yolo_dir / 'requirements.txt'\n",
        "        subprocess.run(['pip', 'install', '-r', str(req_file)], check=True)\n",
        "\n",
        "        data_yaml = {\n",
        "            'train': str(self.images_dir),\n",
        "            'val': str(self.images_dir),\n",
        "            'nc': len(unique_labels),\n",
        "            'names': [str(label) for label in sorted(unique_labels)]\n",
        "        }\n",
        "\n",
        "        data_yaml_path = self.root_dir / 'data.yaml'\n",
        "        with open(data_yaml_path, 'w') as f:\n",
        "            yaml.dump(data_yaml, f)\n",
        "\n",
        "        return data_yaml_path\n",
        "\n",
        "    def train_faster_rcnn(self, image_paths, annotations, num_epochs=1):\n",
        "        model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "        model.to(self.device)\n",
        "        model.train()\n",
        "\n",
        "        dataset = list(zip(image_paths, annotations))\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=2,\n",
        "            shuffle=True,\n",
        "            collate_fn=lambda x: tuple(zip(*x))\n",
        "        )\n",
        "\n",
        "        optimizer = torch.optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=0.005,\n",
        "            momentum=0.9,\n",
        "            weight_decay=0.0005\n",
        "        )\n",
        "\n",
        "        print(\"Starting Faster R-CNN training...\")\n",
        "        for epoch in range(num_epochs):\n",
        "            total_loss = 0\n",
        "            for images, targets in tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "                images = [torchvision.transforms.functional.to_tensor(Image.open(img).convert(\"RGB\")).to(self.device)\n",
        "                         for img in images]\n",
        "                targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                loss_dict = model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                losses.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += losses.item()\n",
        "\n",
        "            avg_loss = total_loss / len(data_loader)\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_yolo(self, data_yaml_path, img_size=640, batch_size=8, epochs=1):\n",
        "        original_dir = os.getcwd()\n",
        "        os.chdir(str(self.yolo_dir))\n",
        "\n",
        "        cmd = [\n",
        "            'python', 'train.py',\n",
        "            '--img', str(img_size),\n",
        "            '--batch', str(batch_size),\n",
        "            '--epochs', str(epochs),\n",
        "            '--data', str(data_yaml_path),\n",
        "            '--weights', 'yolov5s.pt'\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        print(\"YOLOv5 Training Output:\\n\", result.stdout)\n",
        "\n",
        "        os.chdir(original_dir)\n",
        "\n",
        "    def load_trained_yolo(self):\n",
        "        weights_path = self.yolo_dir / 'runs/train/exp/weights/best.pt'\n",
        "        if weights_path.exists():\n",
        "            return torch.hub.load('ultralytics/yolov5', 'custom', path=str(weights_path))\n",
        "        return None\n",
        "\n",
        "    def detect_objects_webcam(self, rcnn_model, yolo_model, label_map):\n",
        "        \"\"\"Run real-time object detection using webcam\"\"\"\n",
        "        rcnn_model.eval()\n",
        "        inv_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "        # Initialize webcam\n",
        "        print(\"Initializing webcam...\")\n",
        "        cap = cv2.VideoCapture(0)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error: Could not open webcam\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    print(\"Error: Could not read frame\")\n",
        "                    break\n",
        "\n",
        "                # Convert BGR to RGB for model input\n",
        "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                pil_image = Image.fromarray(rgb_frame)\n",
        "\n",
        "                # Faster R-CNN detection\n",
        "                rcnn_image = torchvision.transforms.functional.to_tensor(rgb_frame).unsqueeze(0).to(self.device)\n",
        "                with torch.no_grad():\n",
        "                    rcnn_predictions = rcnn_model(rcnn_image)\n",
        "\n",
        "                # YOLOv5 detection\n",
        "                if yolo_model is not None:\n",
        "                    yolo_results = yolo_model(rgb_frame)\n",
        "                    yolo_boxes = yolo_results.xyxy[0].numpy()  # Get bounding boxes\n",
        "\n",
        "                # Draw Faster R-CNN results\n",
        "                for box, label, score in zip(rcnn_predictions[0]['boxes'], rcnn_predictions[0]['labels'], rcnn_predictions[0]['scores']):\n",
        "                    if score >= 0.5:  # Confidence threshold\n",
        "                        x1, y1, x2, y2 = map(int, box.cpu().numpy())\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                        cv2.putText(frame, f\"{inv_label_map[label.item()]}: {score:.2f}\", (x1, y1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "                # Draw YOLO results\n",
        "                for box in yolo_boxes:\n",
        "                    x1, y1, x2, y2, conf, cls = box\n",
        "                    if conf >= 0.5:  # Confidence threshold\n",
        "                        x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                        cv2.putText(frame, f\"{inv_label_map[int(cls)]}: {conf:.2f}\", (x1, y1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "                cv2.imshow('Webcam Object Detection', frame)\n",
        "\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    trainer = ObjectDetectionTrainer()\n",
        "    trainer.download_coco()\n",
        "    images, annotations, unique_labels = trainer.load_dataset()\n",
        "    label_map = trainer.prepare_yolo_dataset(images, annotations, unique_labels)\n",
        "    data_yaml_path = trainer.setup_yolo_training(unique_labels)\n",
        "\n",
        "    # Train models\n",
        "    rcnn_model = trainer.train_faster_rcnn(images, annotations, num_epochs=1)\n",
        "    trainer.train_yolo(data_yaml_path, img_size=640, batch_size=8, epochs=1)\n",
        "\n",
        "    # Load YOLO model\n",
        "    yolo_model = trainer.load_trained_yolo()\n",
        "\n",
        "    # Detect objects using webcam\n",
        "    trainer.detect_objects_webcam(rcnn_model, yolo_model, label_map)\n"
      ]
    }
  ]
}